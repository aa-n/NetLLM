在该项目中，数据集主要用于自适应码率流媒体（ABR）和NetLLM模型的训练和评估。根据README的内容，数据集的格式可以从以下几个部分推测出来：

### 1. **带宽数据集 (`traces`)**
   - **存储位置**：`data/traces/`
   - **格式**：带宽数据集通常是时间序列数据，表示网络吞吐量的变化。每个数据集包含网络带宽随时间变化的值，这些值用于模拟实际的网络条件。它们通常以文件格式存储（例如 CSV、JSON、或特定的二进制格式），并记录每个时刻的带宽情况。
   - **使用场景**：这些带宽数据集被用于模拟视频流的网络条件，帮助训练和测试ABR系统在不同网络环境下的适应性。

### 2. **视频规格 (`videos`)**
   - **存储位置**：`data/videos/`
   - **格式**：视频规格数据集包含视频的不同分辨率和比特率设置，通常包括视频的各个chunk的特征信息，如：
     - 分辨率（例如：720p、1080p等）
     - 每个chunk的比特率（例如：1Mbps, 2Mbps等）
     - 每个chunk的大小（字节数）
   - **使用场景**：这些视频规格用于模拟视频的播放过程，并在ABR算法中根据网络状况选择合适的比特率。

### 3. **经验池 (`exp_pool`)**
   - **存储位置**：`artifacts/exp_pool/`
   - **格式**：经验池存储了ABR系统与环境交互过程中生成的经验数据，这些数据包括：
     - 当前时刻的网络带宽
     - 视频缓冲区的大小
     - 剩余的视频播放部分
     - 动作（选择的码率）
     - 奖励（基于码率和卡顿时间的线性组合）
   - **使用场景**：经验池用于训练NetLLM模型（或其它强化学习模型），帮助模型学习如何根据环境状态（网络状况、视频缓冲等）做出最优的码率选择。

### 4. **模型检查点（Fine-tuned Models）**
   - **存储位置**：`data/ft_plms/`
   - **格式**：这里存储的是已经微调（finetuned）的LLM模型，可以是以 `*.pt` 或其他格式存储的PyTorch模型文件。这些模型通过使用经验池数据进行训练，适应了网络条件优化的任务。

### 5. **自定义数据集**
   - 如果用户想要使用自定义的经验池，首先需要运行 `generate_exp_pool.py` 来生成新的经验池文件。这些文件的格式为pickle（`*.pkl`），并存储了所有与训练过程相关的交互数据（如网络带宽、视频缓冲区、选择的码率等）。

---

### 数据集格式总结：
- **带宽数据集（`traces`）**：时间序列数据，记录带宽随时间变化。
- **视频规格数据集（`videos`）**：包含视频的分辨率、比特率、大小等信息。
- **经验池（`exp_pool`）**：记录ABR决策过程中的环境状态、动作选择及奖励，通常是pickle格式的文件。
- **模型检查点（`ft_plms`）**：训练好的LLM模型文件，通常为`*.pt`格式。

这些数据集的格式通常用于训练NetLLM和ABR强化学习模型，以便根据网络条件和视频播放进度做出最佳码率选择。